# PyTorch AI & ML Fundamentals

A comprehensive collection of implementations covering fundamental to advanced deep learning concepts using PyTorch. This repository documents a complete learning journey from basic perceptrons to modern transformer architectures.

## ğŸ“š Contents

### 1. Foundations
- **Linear Classification** (`1 (linear classification).ipynb`)
  - Basic perceptron implementation
  - Binary classification from scratch
  - Visualization of decision boundaries

- **Tensors** (`2 (tensor).ipynb`)
  - PyTorch tensor operations
  - Tensor manipulation and reshaping
  - Matrix operations fundamentals

- **Perceptron in PyTorch** (`3 (Perceptron_in_torch).ipynb`)
  - Building perceptrons with PyTorch
  - Forward and backward propagation
  - Weight updates and training loops

### 2. Regression
- **Linear Regression** (`4 (linear_regression).ipynb`)
  - From scratch implementation
  - Manual weight updates
  - Loss calculation

- **Linear Regression with Gradient Descent** (`5 (linear_regression_with_gradient).ipynb`)
  - Automatic differentiation with PyTorch
  - Gradient-based optimization
  - Learning rate exploration

- **Unified Regression & Classification** (`6(linear_regression_and_classifier_with_gradient).ipynb`)
  - Using `torch.nn.Linear`
  - SGD optimizer implementation
  - MSE and BCE loss functions

### 3. Classification
- **Linear Classifier in PyTorch** (`7 (Linear Classifier in torch)`)
  - Binary classification with neural networks
  - Sigmoid activation
  - BCEWithLogitsLoss

### 4. Neural Networks
- **Multi-Layer Perceptron for XOR** (`8 (XOR_mlp).ipynb`)
  - Solving non-linearly separable problems
  - Hidden layer architecture
  - ReLU activation functions

- **MLP for MNIST** (`9 (mlp_mnist).ipynb`)
  - Multi-class classification
  - MNIST digit recognition
  - CrossEntropyLoss
  - Model evaluation and accuracy

### 5. Convolutional Neural Networks
- **CNN with Transfer Learning** (`cnn_cifar10_transfer.ipynb`)
  - MobileNetV2 pre-trained model
  - CIFAR-10 classification
  - Fine-tuning strategies
  - Data augmentation

- **CNN for KIE** (`cnn_kie.ipynb`)
  - Custom CNN architecture
  - Advanced image processing

### 6. Transformers
- **Next Word Prediction** (`transformer_next_word.py`)
  - Transformer encoder architecture
  - Positional embeddings
  - Self-attention mechanism
  - Language modeling

- **Sequence-to-Sequence Prompting** (`transformer_seqr_prompt.py`)
  - Advanced transformer applications
  - Prompt engineering
  - Text generation

## ğŸ“ Learning Resources

The repository includes comprehensive PDF materials covering:
- AI & ML Introduction
- ML Classifiers
- Gradient Descent
- Perceptrons
- Activation Functions
- Loss Functions
- XOR Problem
- Tensors

## ğŸš€ Getting Started

### Prerequisites
```bash
pip install torch torchvision torchsummary numpy matplotlib pandas
```

### Running the Notebooks
1. Clone the repository:
```bash
git clone https://github.com/MRaysa/pytorch-AL-ML-fundamentals.git
cd pytorch-AL-ML-fundamentals
```

2. Launch Jupyter:
```bash
jupyter notebook
```

3. Open any notebook and run the cells sequentially

### Running Python Scripts
```bash
python transformer_next_word.py
python transformer_seqr_prompt.py
```

## ğŸ“Š Topics Covered

- âœ… Linear Algebra with Tensors
- âœ… Perceptron Algorithm
- âœ… Linear Regression
- âœ… Logistic Regression
- âœ… Gradient Descent Optimization
- âœ… Backpropagation
- âœ… Multi-Layer Perceptrons
- âœ… Activation Functions (ReLU, Sigmoid)
- âœ… Loss Functions (MSE, BCE, CrossEntropy)
- âœ… Convolutional Neural Networks
- âœ… Transfer Learning
- âœ… Transformer Architecture
- âœ… Self-Attention Mechanism

## ğŸ› ï¸ Technologies

- **PyTorch** - Deep learning framework
- **torchvision** - Computer vision datasets and models
- **NumPy** - Numerical computing
- **Pandas** - Data manipulation
- **Matplotlib** - Data visualization

## ğŸ“ˆ Project Structure

```
pytorch-AL-ML-fundamentals/
â”œâ”€â”€ 1 (linear classification).ipynb
â”œâ”€â”€ 2 (tensor).ipynb
â”œâ”€â”€ 3 (Perceptron_in_torch).ipynb
â”œâ”€â”€ 4 (linear_regression).ipynb
â”œâ”€â”€ 5 (linear_regression_with_gradient).ipynb
â”œâ”€â”€ 6(linear_regression_and_classifier_with_gradient).ipynb
â”œâ”€â”€ 7 (Linear Classifier in torch)
â”œâ”€â”€ 8 (XOR_mlp).ipynb
â”œâ”€â”€ 9 (mlp_mnist).ipynb
â”œâ”€â”€ cnn_cifar10_transfer.ipynb
â”œâ”€â”€ cnn_kie.ipynb
â”œâ”€â”€ transformer_next_word.py
â”œâ”€â”€ transformer_seqr_prompt.py
â”œâ”€â”€ *.pdf (Learning materials)
â””â”€â”€ README.md
```

## ğŸ¯ Learning Path

**Beginner** â†’ Linear Classification, Tensors, Basic Perceptron  
**Intermediate** â†’ Regression, MLP, XOR Problem  
**Advanced** â†’ CNNs, Transfer Learning, Transformers

## ğŸ’¡ Key Concepts Demonstrated

1. **Building from Scratch**: Understanding algorithms by implementing them manually
2. **PyTorch Progression**: Gradual transition from manual implementations to PyTorch modules
3. **Real Datasets**: Working with MNIST, CIFAR-10, and custom datasets
4. **Modern Architectures**: From perceptrons to state-of-the-art transformers
5. **Best Practices**: Proper train/test splits, validation, and model evaluation

## ğŸ¤ Contributing

Feel free to open issues or submit pull requests for improvements!

## ğŸ“ License

This project is open source and available for educational purposes.

## ğŸ‘¤ Author

**MRaysa**

---

â­ Star this repository if you find it helpful for your deep learning journey!
